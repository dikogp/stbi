{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"First I cleaned **\"IMDB data from 2006 to 2016\"**  and added some movies to this data set (some movies from Al Pachino, which was not any in this data set!) and I saved it in a new data set as \"IMDBMovieData.csv\". Here I imported necessary packages to read this data set as *pandas* Dataframe."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n#import matplotlib.pyplot as plt\nimport csv\nfrom sklearn import preprocessing\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ntrainset = pd.read_csv(\"../input/imdb-data-set/IMDBMovieData.csv\", encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01c47a6d9b34a4ce2ab3fd09d77b5d7fe0bbd4f3"},"cell_type":"markdown","source":"Then I **removed some columns** : 'Title', 'ID', 'Votes', 'Year', 'Revenue','Metascore', 'Rating','Description', 'Runtime' because I did not use them in this level of recommendation."},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"d6859e873c2e6a877cc5c99a9f438fcf5f42a51e"},"cell_type":"code","source":"X = trainset.drop(['Title', 'ID', 'Votes', 'Year', 'Revenue','Metascore', 'Rating','Description', 'Runtime'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c97811dab8ff0eef6f2e1e89278dd00a18e3633"},"cell_type":"markdown","source":"\nIn this level of prediction, my program gives recommendations by **Genre , Actors** and **Director** so I got dummies from these tree columns:"},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"7a0148ad85ec195c6db1a59b6bc9a09a4aad71e1"},"cell_type":"code","source":"features = ['Genre','Actors','Director']\nfor f in features:\n    X_dummy = X[f].str.get_dummies(',').add_prefix(f + '.')\n    X = X.drop([f], axis = 1)\n    X = pd.concat((X, X_dummy), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5f0c83548d3e76274ce29311e15f86175e5790b"},"cell_type":"markdown","source":"Here is an **example** of **one movie vector** after concat!!!: As you can see, this movie is in action, adventure, fantasy genre. And it has some actors and director which are not showable in this scale of output."},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"70077fcf1eabfe26e029b78b5d0245f229e62ac4"},"cell_type":"code","source":"import csv\nimport pandas as pd\ntrainset = pd.read_csv(\"../input/imdb-data-set/IMDBMovieData.csv\", encoding='latin-1')\nX = trainset.drop(['Title', 'ID', 'Votes', 'Year', 'Revenue','Metascore', 'Rating','Description', 'Runtime'], axis=1)\nfeatures = ['Genre','Actors','Director']\nfor f in features:\n    X_dummy = X[f].str.get_dummies(',').add_prefix(f + '.')\n    X = X.drop([f], axis = 1)\n    X = pd.concat((X, X_dummy), axis = 1)\nprint (X.loc[5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55e22ad5a48e81b12c873b78d9f3b3257b940160"},"cell_type":"markdown","source":"Then I wrote csv file from Genres, Actors and Directors name from X column (it's name is \"testing\") and then filled it by **giving vote** to each one *I like* or *I hate* by my measurement."},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"869abc236fbe39fcce685a5d758cefa3f6410687"},"cell_type":"code","source":"y = list(X.columns.values)\nwith open('testing.csv', 'w', encoding=\"ISO-8859-1\") as test:\n       write = csv.writer(test, delimiter = \",\")\n       for i in range(3030):\n           write.writerow([y[i]])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3be8bb5f1182c68e1caa1bd8d5aabec4ff58c598"},"cell_type":"markdown","source":"For example in the code bellow, you can run and see first 30 rows of my testing file with my tastes."},{"metadata":{"trusted":true,"_uuid":"80b0b659855dd0220ac7c626eefe0afbf6c87c97"},"cell_type":"code","source":"import pandas as pd\nheader = pd.read_csv(\"../input/votefile/testing.csv\")\nheader.head(30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53959851c1c041476d5dd8314dbb20ad31351d08"},"cell_type":"markdown","source":"Now for similarity measuring I used **Cosine similarity measure** to find out which movie is more similar to my interests, by using this formula: \nsim(x, y) = cos(rx, ry) =\n![image.png](attachment:image.png)\n\nBut since the size of the movies are near, we can **pass up** *denominator *and just compute dot product of our interest (our vote to each actor, director and genre) to each movie vector which is filled with zero or one by existence or absence of each genre, actor and director. I kept these parameters in \"sim\" array.\n\nThen I defined another array named \"similar\" which was built by sorting first n indexes of 'sim' array with maximum parameter value.\n"},{"metadata":{"_uuid":"ecae30850d60b3eeade1e826ee1d23b0f1b955c3"},"cell_type":"markdown","source":"So till now, it is a **complete code** (without making \"testing\" file) which takes data in data frame then drops unnecessary columns then gets dummies from necessary columns and then it makes testing file including all genres, actors and directors for user to vote. Now I run this code with my intrest list (*testing*.csv) :"},{"metadata":{"trusted":true,"_uuid":"f5bcfd2ba3bd9f90fb406c1eaac33b91c02389b7"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport csv\nfrom sklearn import preprocessing\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntrainset = pd.read_csv(\"../input/imdb-data-set/IMDBMovieData.csv\", encoding='latin-1')\nX = trainset.drop(['Title', 'ID', 'Votes', 'Year', 'Revenue','Metascore', 'Rating','Description', 'Runtime'], axis=1)\n#trainset.Revenue = X.Revenue.fillna(X.Revenue.mean())\n#trainset.Metascore= X.Metascore.fillna(X.Revenue.min())\nfeatures = ['Genre','Actors','Director']\nfor f in features:\n    X_dummy = X[f].str.get_dummies(',').add_prefix(f + '.')\n    X = X.drop([f], axis = 1)\n    X = pd.concat((X, X_dummy), axis = 1)\n\ntest = pd.read_csv(\"../input/votefile/testing.csv\")\nT = test.drop(['Content'], axis=1)\nT = T['Vote'].fillna(0)\nvote = T.values\nvec = np.ones((1004,3026), dtype=np.uint8)\nvec = X.values\n\nsim = np.ones((1004,), dtype=np.complex_)\nfor i in range (1,1004):\n    sim[i] = np.inner(vec[i],vote.transpose())\n\nsimilar = sim.argsort()[::-1][:30]\nfor i in range (30):\n    print (trainset.iloc[similar[i],1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae2bf369c1337186749cbe39dec03aff72b0757f"},"cell_type":"markdown","source":"And this is my favorite list based on content! and I think it is right :D But it seems that there are some problems! because the **genre** list is less than **actors**(or directors). I voted to almost all of the genres but most of the actors and directors are without vote. So this list **is more genre based**, for example I like **Keanu Reeves** and I voted to him but there were not any movie of him in this list (maybe because he has not played in my favorite genre ;D ) for solving this problem we can give higher vote to actors (if actors are more important or equal to genre) or normalize the vector of our tastes by these three concepts."},{"metadata":{"_uuid":"19fae8ce5773e804c4d7c00f5036ebcd063bfc7c"},"cell_type":"markdown","source":"Now I define **another recommendation based on a text analysis** which uses \"[Gestalt Pattern Matching](http://collaboration.cmc.ec.gc.ca/science/rpn/biblio/ddj/Website/articles/DDJ/1988/8807/8807c/8807c.htm). To find most similar movies by their **description**. here is the code:"},{"metadata":{"trusted":true,"_uuid":"c59e218432cd8092e6f0323cba3c539a42bdf02a"},"cell_type":"code","source":"import re\nimport difflib\nimport pandas as pd\nimport numpy as np\nimport math\ntrainset = pd.read_csv(\"../input/imdb-data-set/IMDBMovieData.csv\", encoding='latin-1')\ns1 = trainset.iloc[422,3]\ns1w = re.findall('\\w+', s1.lower())\nsim = np.ones((1004,), dtype=np.float)\nfor i in range (1,1004):\n    if i != 422:\n        s2 = trainset.iloc[i,3]\n        if type(s2) == str :\n            s2w = re.findall('\\w+', s2.lower())\n            common = set(s1w).intersection(s2w) \n            common_ratio = 100*(difflib.SequenceMatcher(None, s1w, s2w).ratio())\n            sim[i] = common_ratio    \nM = np.argmax(sim)\nprint (\"your input movie is:\",trainset.iloc[422,1])\nprint (\"My suggestion for you is:\",trainset.iloc[M,1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"673a5b093f692e950d07e6ada2c8439f8e1b5b67"},"cell_type":"markdown","source":"As you see I gave \"*Harry Potter and the Deathly Hallows: Part 1*\" movie and most similar movie by description analysis algorithm was the \"*Harry Potter and the Deathly Hallows: Part 2*\" and it seems to be right!:D"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}